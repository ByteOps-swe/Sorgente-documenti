\subsubsection{Apache Kafka}
Apache Kafka è una piattaforma open-source di streaming distribuito sviluppata dall'Apache Software Foundation. Progettata per gestire flussi di dati in tempo reale in modo scalabile e affidabile, è ampiamente utilizzata nel data streaming e nell'integrazione dei dati nelle moderne applicazioni.

\paragraph{Versione}
La versione utilizzata è: 3.7.0
\paragraph{Documentazione}
\href{https://kafka.apache.org/20/documentation.html}{https://kafka.apache.org/20/documentation.html}

\paragraph{Funzionalità e vantaggi di Apache Kafka}
Le principali funzionalità e vantaggi di Apache Kafka includono:

\begin{itemize}
  \item \textbf{Pub-Sub Messaging:} Kafka utilizza un modello di messaggistica publish-subscribe, dove i produttori di dati inviano messaggi ad uno o più topic e i consumatori possono sottoscriversi a tali topic per ricevere i messaggi;
  
  \item \textbf{Disaccoppiamento Produttore - Consumatore:} questo principio si realizza grazie al fatto che i Produttori e i Consumatori non necessitano di essere consapevoli l'uno dell'altro o di interagire direttamente. Invece, essi comunicano attraverso il broker Kafka, che svolge il ruolo di intermediario per la trasmissione dei messaggi. Ciò consente una maggiore scalabilità e flessibilità nell'architettura del sistema, facilitando la gestione e il mantenimento delle applicazioni;
  
  \item \textbf{Architettura Distribuita:} Kafka è progettato per essere distribuito su un cluster di nodi, consentendo una scalabilità orizzontale per gestire grandi volumi di dati e carichi di lavoro. Questo approccio distribuito offre resilienza e alta disponibilità, garantendo che il sistema possa crescere in modo flessibile con l'aumentare delle richieste;
  
  \item \textbf{Persistenza e Affidabilità:} Kafka offre la possibilità di definire politiche specifiche per la conservazione dei dati, garantendo la durabilità dei messaggi. Questo non solo assicura la disponibilità dei dati anche in caso di eventuali interruzioni del servizio, ma consente anche ai consumatori di recuperare i messaggi dopo tali anomalie, garantendo un alto livello di affidabilità nel sistema.
  
  \item \textbf{Alta Disponibilità:} Kafka assicura un'elevata disponibilità e tolleranza ai guasti grazie alla sua architettura distribuita e al meccanismo di replica dei dati. Anche in caso di malfunzionamenti dei nodi o delle componenti, i cluster di Kafka mantengono la loro operatività, garantendo la continuità del servizio.
  
  \item \textbf{Elaborazione degli Stream:} Kafka supporta anche l'elaborazione degli stream di dati in tempo reale tramite API come Kafka Streams e Kafka Connect, consentendo agli sviluppatori di scrivere applicazioni per l'analisi e l'elaborazione dei dati in tempo reale.
\end{itemize}

\paragraph{Casi d'uso di Apache Kafka}

Apache Kafka è utilizzato in una vasta gamma di casi d'uso, tra cui:

\begin{itemize}
  \item \textbf{Data Integration:} Kafka viene utilizzato per integrare dati provenienti da diverse fonti e sistemi, consentendo lo scambio di dati in tempo reale tra applicazioni e sistemi eterogenei.
  
  \item \textbf{Streaming di Eventi:} Molte applicazioni moderne, come le applicazioni IoT (Internet of Things) e le applicazioni di monitoraggio in tempo reale, utilizzano Kafka per lo streaming di eventi in tempo reale e l'analisi dei dati.
  
  \item \textbf{Analisi dei Log:} Kafka è spesso utilizzato per l'analisi dei log di sistema e applicativi in tempo reale, consentendo il monitoraggio delle prestazioni, la rilevazione degli errori e l'analisi dei pattern di utilizzo.
  
  \item \textbf{Elaborazione di Big Data:} Kafka è integrato con tecnologie di big data come Apache Hadoop e Apache Spark, consentendo l'elaborazione di grandi volumi di dati in tempo reale.
  
  \item \textbf{Messaggistica Real-time:} Kafka è ampiamente utilizzato per la messaggistica real-time in applicazioni di social media, e-commerce e finanziarie, dove la velocità e l'affidabilità della messaggistica sono cruciali.
\end{itemize}

\paragraph{Utilizzo nel progetto}
\textit{Kafka} funge da intermediario dei messaggi, ricevendo i dati dai produttori e rendendoli disponibili ai consumatori. Nel contesto del progetto, i dati provenienti dalle simulazioni di sensori vengono inviati a \textit{Kafka} come messaggi in formato \textit{JSON}.

\paragraph*{Consumatori di dati:}
\begin{itemize}
  \item \textbf{\textit{ClickHouse:}} \textit{Kafka} invia \todo{è Kafka che li invia o i consumatori che se li prendono da Kafka?} i dati ai consumatori, inclusi i database come \textit{ClickHouse}, dove i dati vengono salvati per l'analisi e l'archiviazione a lungo termine.
  \item \textbf{\textit{Faust:}} per soddisfare il requisito opzionale del calcolo del punteggio di salute, \textit{Kafka} rende disponibili i dati in tempo reale a un'applicazione di Faust\todo{è corretto applicazione di Faust?}. Quest'ultima elabora i dati utilizzando una funzione di aggregazione per calcolare il punteggio e quindi mette a disposizione il risultato in una coda dedicata di Kafka per i servizi interessati.
\end{itemize}

In breve, \textit{Kafka} funge da ponte tra i produttori di dati (simulazioni di sensori) e i consumatori di dati (\textit{ClickHouse} o altri servizi futuri). Gestisce il flusso dei dati in tempo reale e garantisce che i dati siano disponibili per l'elaborazione e la visualizzazione in modo efficiente e scalabile.